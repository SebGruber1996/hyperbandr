---
title: "hyperbandr tutorial"
author: "Niklas"
date: "23 MÃ¤rz 2018"
output: pdf_document
header-includes:
  - \usepackage{graphicx}
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Hyperbandr Package

This is an R6 implementation of the original **hyperband** algorithm  <https://arxiv.org/abs/1603.06560>.

R6 is an encapsulated object oriented system akin to those in Java or C++, where objects contain methods in addition to data, and those methods can modify objects directly (unlike S3 and S4 which are both functional object-oriented systems, where class methods are separate from objects, and objects are not mutable).

Essentially, that means that we obtain a very generic implementation, which is working with every other R package (as long the algorithm meets the requirements of hyperband).

## This tutorial consists of four examples:

* hyperbandr to optimize the **branin function**
* hyperbandr to optimize **xgboost**
* hyperbandr to optimize a **neural network**
* hyperbandr in combination with MBO to optimite a **neural network**

\newpage
## Example 1: hyperbandr to optimize the **branin function**

```{r, echo = TRUE, message = FALSE}
library("smoof")
library("data.table")
library("ggplot2")
```

```{r, echo = TRUE, fig.height = 3.6, fig.width = 6}
problem = makeBraninFunction()

# the branin function has 3 global minima (red dots)
opt = data.table(x1 = getGlobalOptimum(problem)$param$x1, 
                 x2 = getGlobalOptimum(problem)$param$x2)

(vis = autoplot(problem) + 
    geom_point(data = opt, aes(x = x1, y = x2), shape = 20, colour = "red", size = 5))
```


We treat the value of $x_1$ as our "configuration" and try to find the optimal value for $x_2$, our "hyperparameter" (reminder: in hyperband we sample random configurations in each bracket).

So in order to apply $\textbf{hyperbandr}$ on that problem, we need to define a hyperparameter space and four specific functions.

### Configuration Space

As our very first step, we need to define the hyperparameter space to sample our configurations from.
We want to obtain random values between -5 and approximately 10.1 (our $x_1$ axis..)

```{r, echo = TRUE}
# we use the makeParamSet function from the ParamHelpers package
configSpace = makeParamSet(
    makeNumericParam(id = "x1", lower = -5, upper = 10.1))
```

### Function 1: the sampling function

Now we need a function to sample configurations from the configuration space

```{r, echo = TRUE}
# par.set: the parameter space to sample from
# n.configs: the amount of configs to sample
# ...: additional parameters (see example ...........)
sample.fun = function(par.set, n.configs, ...) {
  sampleValues(par = par.set, n = n.configs)
}
```

### Function 2: the initialization function

This function takes a config and samples a corresponding value of $x_2$ in order to initialize the model

```{r, echo = TRUE}
# r: initial budget used for the initialization
# config: one configuration sampled by sample.fun
init.fun = function(r, config) {
  x1 = unname(unlist(config))
  x2 = runif(1, 0, 15)
  mod = c(x1, x2)
  return(mod)
}
```

### Function 3: the training function

To train our model, we simply sample values from a normal distribution and add or subtract them from our current $x_2$.
If the performance improves, we keep the model, else we discard it and keep the old one.

```{r, echo = TRUE}
# mod: the model to train
# budget: number of iterations to train the model for
train.fun = function(mod, budget) {
  for(i in seq_len(budget)) {
    mod.new = c(mod[[1]], mod[[2]] + rnorm(1, sd = 3))
    if(performance.fun(mod.new) < performance.fun(mod))
      mod = mod.new
  }
  return(mod)
}
```

### Function 4: the performance function

Finally, we define a function to evaluate the performance of each model

```{r, echo = TRUE}
# model: the model to evaluate
performance.fun = function(model) {
  problem(c(model[[1]], model[[2]]))
}
```

### Apply hyperbandr (since the problem to optimize here is very easy, the execution will only take 1-2 seconds)

```{r, echo = TRUE, message = FALSE}
library("R6")
library("devtools")
load_all()
```

```{r, echo = TRUE}
hyperhyper = hyperband(
  max.ressources = 81,
  prop.discard = 3,
  max.perf = FALSE,
  id = "branin",
  par.set = configSpace,
  sample.fun =  sample.fun,
  train.fun = train.fun,
  performance.fun = performance.fun)
```

\newpage
Let us inspect the results: we obtain a list of 5 R6 objects.

```{r, echo = TRUE}
hyperhyper
```

We could inspect the best configuration of bracket 3:

```{r, echo = TRUE}
hyperhyper[[3]]$models[[1]]$model
```

Or the first three configurations of bracket 2:

```{r, echo = TRUE}
hyperhyper[[2]]$configurations[1:3]
```

\newpage
Let us carry out a benchmark and repeat hyperband for 100 times to see if all brackets perform equally well.

```{r, echo = FALSE, message = FALSE, results = "hide"}
benchmarkThis = function(howManyIt = 10L) {
  results = data.frame(matrix(ncol = 5, nrow = howManyIt))
  for (i in 1:howManyIt) {
    catf("Iteration %i", i)
    hyperhyper = hyperband(
      max.perf = FALSE,
      max.ressources = 81,
      prop.discard = 3,
      id = "branin",
      par.set = configSpace,
      sample.fun =  sample.fun,
      train.fun = train.fun,
      performance.fun = performance.fun)
    results[i, 1] = round(hyperhyper[[1]]$getPerformances(), digits = 2)
    results[i, 2] = round(hyperhyper[[2]]$getPerformances(), digits = 2)
    results[i, 3] = round(hyperhyper[[3]]$getPerformances(), digits = 2)
    results[i, 4] = round(hyperhyper[[4]]$getPerformances(), digits = 2)
    results[i, 5] = round(hyperhyper[[5]]$getPerformances(), digits = 2)
  }
  return(results)
}

myBraninBenchmark = benchmarkThis(100)
```

```{r, echo = FALSE, message = FALSE}
ggplot(stack(myBraninBenchmark), aes(x = ind, y = values, fill = ind)) +
  scale_x_discrete(labels=c("bracket 1","bracket 2","bracket 3","bracket 4", "bracket 5")) +
  theme(legend.position = "none") + labs(x = "", y = "performance") +
  geom_boxplot()
```

Unsurprisingly, the fewer configurations are drawn, the worse the results become.

\newpage
## Example 2: hyperbandr to optimize **xgboost**

```{r, echo = TRUE, message = FALSE}
library("mlr")
library("xgboost")
library("ggplot2")
library("gridExtra")
library("dplyr")
```

```{r, echo = TRUE}
data(agaricus.train)
data(agaricus.test)
dtrain = xgb.DMatrix(agaricus.train$data, label = agaricus.train$label)
dtest = xgb.DMatrix(agaricus.test$data, label = agaricus.test$label)
```

```{r, echo = TRUE}
# config space
configSpace = makeParamSet(
  makeIntegerParam("max_depth", lower = 3, upper = 15, default = 3),
  makeNumericParam("colsample_bytree", lower = 0.3, upper = 1, default = 0.6),
  makeNumericParam("subsample", lower = 0.3, upper = 1, default = 0.6))

# sample fun
sample.fun = function(par.set, n.configs, ...) {
  lapply(sampleValues(par = par.set, n = n.configs), function(x) x[!is.na(x)])
}

# init fun 
init.fun = function(r, config) {
  watchlist = list(eval = dtest, train = dtrain)
  capture.output({mod = xgb.train(config, dtrain, nrounds = r, watchlist, verbose = 1)})
  return(mod)
}

# train fun
train.fun = function(mod, budget) {
  watchlist = list(eval = dtest, train = dtrain)
  capture.output({mod = xgb.train(xgb_model = mod, 
    nrounds = budget, params = mod$params, dtrain, watchlist, verbose = 1)})
  return(mod)
}

# performance fun
performance.fun = function(model) {
  tail(model$evaluation_log$eval_rmse, n = 1)
}
```

```{r, echo = TRUE}
#### make xgboost algorithm object ####
obj = algorithm$new(
  id = "xgboost",
  configuration = sample.fun(par.set = configSpace, n.configs = 1)[[1]],
  initial.budget = 1,
  init.fun = init.fun,
  train.fun = train.fun,
  performance.fun = performance.fun)
```

```{r, echo = TRUE}
# we can inspect model of our algorithm object
obj$model
```

```{r, echo = TRUE}
# the data matrix shows us the hyperparameters, the current budget and the performance
obj$algorithm.result$data.matrix
```

```{r, echo = TRUE}
# if we are only interested in the performance, we can also call the getPerformance method
obj$getPerformance()
```

```{r, echo = TRUE}
# we can continue training our object for one iteration by calling
obj$continue(1)
```

```{r, echo = TRUE}
# inspect of the data matrix has changed
obj$algorithm.result$data.matrix
```

```{r, echo = TRUE, message = FALSE, warning = FALSE}
# continue training for 18 iterations to obtain a total of 20 iterations
invisible(capture.output(replicate(18, obj$continue(1))))
```

```{r, echo = TRUE}
# inspect model the model again
obj$model
```

```{r, echo = TRUE}
# inspect the data matrix again
obj$algorithm.result$data.matrix
```

```{r, echo = TRUE}
# we can immediately visualize the performance function
obj$visPerformance()
```

```{r, echo = TRUE}
###### make xgboost bracket object #####
brack = bracket$new(
  max.perf = FALSE,
  max.ressources = 81,
  prop.discard = 3,
  s = 4,
  B = (4 + 1)*81,
  id = "xgboost",
  par.set = configSpace,
  sample.fun = sample.fun,
  train.fun = train.fun,
  performance.fun = performance.fun)
```

```{r, echo = TRUE}
# the data matrix shows us the hyperparameters, the current budget and the performance
brack$bracket.storage$data.matrix
```

```{r, echo = TRUE, message = FALSE, warning = FALSE}
# run the bracket
brack$run()
```

```{r, echo = TRUE}
# inspect the data matrix again
brack$bracket.storage$data.matrix
```

```{r, echo = TRUE}
# visualize the the bracket
brack$visPerformances()
```

```{r, echo = TRUE}
# access the performance of the best model
brack$getPerformances()
```

```{r, echo = TRUE, message = FALSE, warning = FALSE}
########### call hyperband ############ 
hyperhyper = hyperband(
  max.ressources = 81, 
  prop.discard = 3,  
  max.perf = FALSE,
  id = "xgboost", 
  par.set = configSpace, 
  sample.fun =  sample.fun,
  train.fun = train.fun, 
  performance.fun = performance.fun)
```

```{r, echo = TRUE}
# visualize the brackets and get the best performance of each bracket
hyperVis(hyperhyper, rows = 3, cols = 2)
lapply(hyperhyper, function(x) x$getPerformances())
```


\newpage
## Example 3: hyperbandr to optimize a **neural network**

```{r, echo = TRUE, message = FALSE}
library("mxnet") 
library("mlr") # you might need to install mxnet branch of mlr: devtools::install_github("mlr-org/mlr", ref = "mxnet")
library("data.table")
```

```{r, echo = TRUE}
# read mini_mnist (1/10 of actual mnist for faster evaluation, evenly distributed classes)
train = fread("mnist/train.csv", header = TRUE)
test = fread("mnist/test.csv", header = TRUE)

# Some operations to normalize features
mnist = as.data.frame(rbind(train, test))
mnist = mnist[sample(nrow(mnist)), ]
mnist[, 2:785] = lapply(mnist[, 2:785], function(x) x/255) 
rm(train)
rm(test)

# Generate train and test split
train.set = sample(nrow(mnist), size = (2/3)*nrow(mnist))
test.set = setdiff(1:nrow(mnist), train.set)

# mini-mnist has 10 classes
problem = makeClassifTask(data = mnist, target = "label")

# each class has 600 samples
print(problem)
```

```{r, echo = TRUE}
configSpace = makeParamSet(
  makeNumericParam(id = "learning.rate", lower = 0.01, upper = 0.5),
  makeNumericParam(id = "momentum", lower = 0.1, upper = 0.99),
  makeIntegerParam(id = "layers", lower = 1L, upper = 2L),
  makeIntegerParam(id = "num.layer1", lower = 4L, upper = 8L),
  makeIntegerParam(id = "num.layer2", lower = 8L, upper = 16L),
  makeDiscreteParam(id = "act1", c("tanh", "relu", "sigmoid")),
  makeDiscreteParam(id = "act2", c("tanh", "relu", "sigmoid")))

# sample fun
sample.fun = function(par.set, n.configs, ...) {
  lapply(sampleValues(par = par.set, n = n.configs), function(x) x[!is.na(x)])
}

# init fun
init.fun = function(r, config) {
  lrn = makeLearner("classif.mxff", begin.round = 1, num.round = r, par.vals = config)
  mod = train(learner = lrn, task = problem, subset = train.set)
  return(mod)
}

# train fun
train.fun = function(mod, budget) {
  lrn = makeLearner("classif.mxff", par.vals = mod$learner$par.vals)
  lrn = setHyperPars(lrn,
    symbol = mod$learner.model$symbol,
    arg.params = mod$learner.model$arg.params,
    aux.params = mod$learner.model$aux.params,
    begin.round = mod$learner$par.vals$begin.round + mod$learner$par.vals$num.round,
    num.round = budget)
  mod = train(learner = lrn, task = problem, subset = train.set)
  return(mod)
}

# performance fun
performance.fun = function(model) {
  pred = predict(model, task = problem, subset = test.set)
  performance(pred, measures = acc)
}
```

```{r, echo = TRUE}

```

```{r, echo = TRUE}

```

```{r, echo = TRUE}

```

```{r, echo = TRUE}

```

```{r, echo = TRUE}

```

```{r, echo = TRUE}

```

```{r, echo = TRUE}

```

```{r, echo = TRUE}

```

```{r, echo = TRUE}

```

```{r, echo = TRUE}

```

```{r, echo = TRUE}

```

```{r, echo = TRUE}

```

```{r, echo = TRUE}

```

```{r, echo = TRUE}

```

```{r, echo = TRUE}

```

```{r, echo = TRUE}

```

```{r, echo = TRUE}

```




