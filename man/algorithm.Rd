% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Algorithm.R
\docType{data}
\name{algorithm}
\alias{algorithm}
\title{R6 class to create algorithm objects}
\format{\code{\link{R6Class}} object}
\usage{
algorithm
}
\value{
Algorithm object
}
\description{
An \code{\link[R6]{R6Class}} to be optimized by hyperband
}
\section{Fields}{

\describe{
\item{\code{id}}{[\code{string}]\cr
An id for the Algorithm object}

\item{\code{configuration}}{\cr
The configuration to use}

\item{\code{initial.budget}}{\cr
The budget to use for the initialization of the model}

\item{\code{init.fun}}{\cr
The function to initialize the model}

\item{\code{train.fun}}{\cr
The function to carry out training}

\item{\code{performance.fun}}{The function to measure the performance}
}}

\section{Methods}{

\code{$continue(budget)} continue training for \code{budget} iterations  \cr
\code{$getPerformance()} computes the performance of the model \cr
}

\examples{
# simple example for the branin function (minimization problem)
library("smoof")
problem = makeBraninFunction()

# the red crosses are the three global minima:
opt = data.table(x1 = getGlobalOptimum(problem)$param$x1, x2 = getGlobalOptimum(problem)$param$x2)
(vis = autoplot(problem) 
  + geom_point(data = opt, aes(x = x1, y = x2), 
               shape = 4, colour = "red", size = 5) ) 

# we choose a random x1 as our hyperpamater and optimize x2
configuration = runif(1, -5, 10.1)
 
# model initialization function:
init.fun = function(r, config) {
  x1 = unname(unlist(config))
  x2 = runif(1, 0, 15)
  mod = c(x1, x2)
  return(mod)
}

# training function:
train.fun = function(mod, budget) {
  for(i in seq_len(budget)) {
    mod.new = c(mod[[1]], mod[[2]] + rnorm(1, sd = 3))
    if(performance.fun(mod.new) < performance.fun(mod))
      mod = mod.new
  }
  return(mod)
}

# performance function:
performance.fun = function(model) {
  problem(c(model[[1]], model[[2]]))
}

# create the algorithm object
obj = algorithm$new(
  id = "branin",
  configuration = configuration,
  initial.budget = 0,
  init.fun = init.fun,
  train.fun = train.fun,
  performance.fun = performance.fun
)

# get the performance of the model
obj$getPerformance()

# continue training for 100 iterations and get new performance
obj$continue(100)
obj$getPerformance()

# visualize the results (blue: result of the retrained model)
opt = data.table(x1 = getGlobalOptimum(problem)$param$x1, x2 = getGlobalOptimum(problem)$param$x2)
(vis = autoplot(problem) 
  + geom_point(data = opt, aes(x = x1, y = x2), 
               shape = 4, colour = "red", size = 5) 
  + geom_point(aes(x = obj$model[[1]], y = obj$model[[2]]), 
               shape = 4, colour = "blue", size = 5))
}
\keyword{datasets}
